{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# ðŸ¦œðŸ”— LangChain agent using plan and solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_experimental.plan_and_execute import PlanAndExecute, load_agent_executor, load_chat_planner\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain import SerpAPIWrapper\n",
    "from langchain.agents.tools import Tool\n",
    "from langchain.tools import tool\n",
    "from langchain import LLMMathChain\n",
    "from langchain.agents import load_tools,initialize_agent, AgentType\n",
    "from langchain.utilities.jira import JiraAPIWrapper\n",
    "from langchain.agents.agent_toolkits.jira.toolkit import JiraToolkit\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools(\n",
    "    [\"serpapi\", \"human\"]\n",
    ")\n",
    "\n",
    "jira = JiraAPIWrapper()\n",
    "jiratoolkit = JiraToolkit.from_jira_api_wrapper(jira)\n",
    "llm = AzureChatOpenAI(deployment_name=\"gpt-35-turbo\", \n",
    "                       api_version=\"2023-07-01-preview\",\n",
    "                       temperature=0)\n",
    "\n",
    "jiraagent = initialize_agent(\n",
    "    jiratoolkit.get_tools(), llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "@tool(\"save\", return_direct=True)\n",
    "def save(userstories: list[str]) -> str:\n",
    "    \"\"\"Saves a list of user story into the backlog.\"\"\"\n",
    "    for userstory in userstories:\n",
    "        jiraagent.run(f\"create a new story in project TICTACTOE: {userstory}.\")\n",
    "    return \"Done.\"\n",
    "\n",
    "tools = tools + [save]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AzureChatOpenAI(\n",
    "                        deployment_name=\"gpt-4\", \n",
    "                        api_version=\"2023-07-01-preview\",\n",
    "                        temperature=0.0)\n",
    "planner = load_chat_planner(model)\n",
    "executor = load_agent_executor(model, tools, verbose=True)\n",
    "agent = PlanAndExecute(planner=planner, executor=executor, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"Create a backlog for a tictactoe game. When you are done save the final user stories to the backlog.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
