{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wieso LangChain und LangGraph\n",
    "\n",
    "Wieso gibt es diese Abstraktionen LangChain und LangGraph.\n",
    "\n",
    "Das hat vornehmlich historische Gründe.\n",
    "\n",
    "- LangChain ganz zu Anfang hat einfach nur versucht, einheitliche Interfaces für LLMs, VectorStores etc. bereit zu stellen und daraus vorgefertigte Chains zu bauen.\n",
    "- Damals gab es noch keine LCEL (Diese lustige Operatorschreibweise mit den Pipes |)\n",
    "- Dann kam die LCEL und aus Chains wurden Runnables.\n",
    "- Es war immer noch mit Schwierigkeiten verbunden, elegant den Datenfluss in einem Agenten zu steuern. Die LCEL war dafür einfach nicht gebaut, aber die Anforderungen gingen immer mehr in Richtung Agent.\n",
    "- Daher die Idee, speziell für agentische, zyklische Anwendungen neue Abstraktionen zu bauen.\n",
    "\n",
    "Nun leben die LCEL und LangGraph nebeneinander her. Man möchte meist beides in größeren Anwendungen benutzen. Die beiden Baukästen haben auch viele gemeinsame Schnittpunkte:\n",
    "\n",
    "- Das Callback-System\n",
    "- Das Config-Objekt\n",
    "- Ein Graph ist auch ein Runnable\n",
    "- Langsmith-Tracing\n",
    "\n",
    "Legacy-Chains im LangChain-Repo, die nicht mit LCEL oder LangGraph gebaut sind werden je nach Fleiß der Commnity schrittweise umgebaut. Die alten Chains werden dann nicht mehr gepflegt.\n",
    "\n",
    "Mit den schnell besser werdenden LLMs ändern sich die Möglichkeiten und die Anforderungen an Frameworks.\n",
    "\n",
    "Vielleicht sieht LangChain in zwei Jahren schon wieder ganz anders aus oder ist überhaupt nicht mehr das Tooling der Wahl.\n",
    "\n",
    "Damit muss man leben können. Aktuell findet LangChain allerdings sehr großen Anklang. Machen wir uns also die Mühe und schauen etwas unter die Motorhaube.\n",
    "\n",
    "#### Die LCEL kennen wir schon:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import llm\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Hello friend! Please tell me a joke about {topic}\"\n",
    ")\n",
    "\n",
    "lcel_chain = prompt | llm() | StrOutputParser()\n",
    "\n",
    "print(lcel_chain.invoke({\"topic\": \"chickens\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nun wollen wir uns LangGraph anschauen\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
