{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e218d63d-0e47-4ad3-90ef-03d085ffa77f",
   "metadata": {},
   "source": [
    "# ðŸ¦œðŸ”— Langchain Demo\n",
    "\n",
    "Welcome! This example will give you a first look at langchain. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f051dad0-71d4-4c77-a382-037ffe7e6f32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ab7ed6-9ab1-449c-bd8d-26da0422472b",
   "metadata": {},
   "source": [
    "Import langchains adaptor to openai, the prompttemplate interface and llmchain support - and get the api key from the .env file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c066b0f-3a32-457b-a73f-471b4c74e9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc660189-9ee6-45b6-80f6-95abcdf0b145",
   "metadata": {},
   "source": [
    "Let OpenAi predict what should come next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac177b4-e0fa-460a-9a79-d7c6cc7bb8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(deployment_name=\"gpt-35-turbo\",)\n",
    "llm.predict(\"Hi OpenAI! Kannst Du mir gerade mal einen frÃ¤nkischen Trinkspruch im Dialekt erzeugen?\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "de8b3a81-a232-48e2-bdc4-0b5ceee5ad13",
   "metadata": {},
   "source": [
    "PromptTemplates are a - quite simple - abstraction to merge variables and allows prompt repositories like langchain hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd72dfa-3212-4b4a-a9b3-a2993c9c0b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"ort\", \"beruf\"],\n",
    "    template=\"Du bist ein {beruf} aus Franken. ErklÃ¤r in 2 SÃ¤tzen in frÃ¤nkischem dialekt warum Deine Kunden aus {ort} die besten sind.\",\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "print(chain.run({\n",
    "    'beruf': \"BÃ¤cker\",\n",
    "    'ort': \"WÃ¼rzburg\"\n",
    "    }))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71f18e1-6ed7-4f05-a47f-ba552f8b39f2",
   "metadata": {},
   "source": [
    "Just go ahead and play a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9186897d-df7a-4149-afd3-510ebdd911e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.run({\n",
    "    'beruf': \"Programmierer\",\n",
    "    'ort': \"Stuttgart\"\n",
    "    }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
