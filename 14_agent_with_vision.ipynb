{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü¶úüîó Multimodale LLMs (Vision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.prompts import MessagesPlaceholder, SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "from helpers import llm, formatted_output_streamer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bilder malen mit Dall-E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    HumanMessagePromptTemplate.from_template(\"Generate a short prompt to generate an image based on the following description: {image_desc}\")\n",
    "])\n",
    "chain = prompt | llm(temperature=0.9) | StrOutputParser()\n",
    "instruction = chain.invoke({\"image_desc\":\"halloween night at a haunted museum\"})\n",
    "print(instruction)\n",
    "\n",
    "image_url = DallEAPIWrapper(model=\"dall-e-2\", size=\"256x256\").run(instruction) # Das \"run\" ist ein altes Interface, der DallEAPIWrapper ist scheinbar nicht aktuell. Das alte \"run\" ist das Pendant zum neueren \"invoke\"\n",
    "print(str(image_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bilder beschreiben mit gpt-4-vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_llm = llm(model=\"gpt-4-vision-preview\", max_tokens=1024)\n",
    "vision_prompt = ChatPromptTemplate.from_messages([\n",
    "    HumanMessagePromptTemplate.from_template([\"{input}\", {\"image_url\": \"{image_url}\"}])\n",
    "])\n",
    "vision_chain = vision_prompt | vision_llm | StrOutputParser()\n",
    "\n",
    "inputs = {\"input\": \"What's in this image?\", \"image_url\" : \"https://joscha.com/data/media/cartoons/130608.png\"}\n",
    "print(vision_chain.invoke(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Man kann so etwas nat√ºrlich auch als Tool in einem Agenten einsetzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import StructuredTool\n",
    "\n",
    "def analyze_image(image_path: str, question:str )-> str:\n",
    "    \"\"\"This tool can extract general information from an image given a query.\"\"\"\n",
    "    base64_image = encode_image(image_path)\n",
    "    inputs = {\"input\": f\"{question}\", \"image_url\" : f\"data:image/jpeg;base64,{base64_image}\"}  # Das ist die richtige Syntax f√ºr lokale Bilder\n",
    "    return vision_chain.invoke(inputs)\n",
    "\n",
    "tools = [StructuredTool.from_function(analyze_image)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_agent_executor\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(\"You are a helpful assisstant.\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
    "        MessagesPlaceholder('agent_scratchpad')\n",
    "    ]\n",
    ")\n",
    "\n",
    "agent_runnable = create_openai_functions_agent(llm(temperature=0), tools, prompt)\n",
    "agent_executor = create_agent_executor(agent_runnable, tools) | formatted_output_streamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"input\": \"Mein Ticket ist hier: DBTicket.jpg. Wann sollte ich wo am Bahnhof sein?\"}\n",
    "async for chunk in agent_executor.astream(inputs):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pers√∂nliche Daten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"input\": \"Mein Ticket ist hier: DBTicket.jpg. Ich kann schlecht lesen, gib mir bitte die Auftragsnummer zur√ºck?\"}\n",
    "async for chunk in agent_executor.astream(inputs):\n",
    "    print(chunk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
