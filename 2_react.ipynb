{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# ü¶úüîó LangChain React Agent Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "In diesem Part schauen wir uns das Thema Agenten an. Dabei nutzten wir das neueste Langchain Format f√ºr Agenten, LangGraph. Mit LangGraph k√∂nnen Agenten als Graphen modelliert werden.\n",
    "\n",
    "Um die Komplexit√§t gering zu halten, verwenden wir in diesen Beispielen prebuilt Agent- und Tool-Executors, die von Langchain bereit gestellt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Pakete installieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Umgebungsvariablen laden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Tools:\n",
    "\n",
    "Mit Tools erlangt der Agent zus√§tzliche F√§higkeiten und Wissen, die √ºber die vorhandenen F√§higkeiten des eingesetzten Sprachmodells hinausgehen. Tools werden dabei vom Agenten immer eigenst√§ndig eingesetzt.\n",
    "\n",
    "Wie vorab erw√§hnt, nutzen wir einen Prebuilt Tool-Executor um die Komplexit√§t gering zu halten.\n",
    "\n",
    "Als Tool setzen wir hier eine Websuche √ºber DuckduckGo ein. Dadurch erlangt der Agent die F√§higkeit Informationen aus dem Internet zu recherchieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolExecutor\n",
    "from langchain_community.tools.ddg_search.tool import DuckDuckGoSearchRun\n",
    "\n",
    "tools = [DuckDuckGoSearchRun()]\n",
    "tools_executor = ToolExecutor(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Agent\n",
    "\n",
    "In diesem Schritt erstellen wir den Agenten selbst. \n",
    "\n",
    "Hierf√ºr ben√∂tigen wir ein LLM mit dem der Agent ausgef√ºhrt werden soll. **Wichtig** ist hierbei, dass das Sprachmodell auf die Ausf√ºhrung von Agenten-Logik trainiert sein muss. Wir verwenden in diesem Beispiel die Modelle von OpenAI, da diese optimal f√ºr die Ausf√ºhrung von Agenten-Logik geeignet sind.\n",
    "\n",
    "Damit LangGraph die Agenten-Logik ausf√ºhren kann, ben√∂tigen wir einen Agent-Executor. Auch hier nutzen wir einen Prebuilt Agent-Executor, in diesem Beispiel einen der OpenAI Functions ausf√ºhren kann.\n",
    "\n",
    "Mit .stream f√ºhren wir den Graphen aus und geben uns die einzelen Steps des Agentenlaufs aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import chat_agent_executor\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from helpers import llm\n",
    "\n",
    "# app = chat_agent_executor.create_tool_calling_executor(llm, tools_executor)\n",
    "model = llm()\n",
    "app = chat_agent_executor.create_function_calling_executor(model, tools)\n",
    "\n",
    "inputs = {\"messages\": [HumanMessage(content=\"Wann wurde Dieter Bohlen geboren? Wann seine Frau? Was ist die Altersdifferenz?\")]}\n",
    "\n",
    "for s in app.stream(inputs):\n",
    "    print(list(s.values()))\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "In diesem Beispiel f√ºhren wir den zuvor definierten Agenten nochmals aus und streamen diesmal allerdings nur die finale Antwort des Agentenlauf raus. Dabei wird die Antwort Token f√ºr Token ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.prebuilt import chat_agent_executor\n",
    "from helpers import graph_agent_llm_output_streamer_events, llm\n",
    "\n",
    "inputs = {\"messages\": [HumanMessage(content=\"Wann wurde Dieter Bohlen geboren? Wann seine Frau? Was ist die Altersdifferenz?\")]}\n",
    "\n",
    "model = llm()\n",
    "\n",
    "app = chat_agent_executor.create_function_calling_executor(model, tools)\n",
    "\n",
    "await graph_agent_llm_output_streamer_events(app, inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
